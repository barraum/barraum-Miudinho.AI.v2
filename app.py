import streamlit as st
import google.generativeai as genai
import faiss
import pickle
import numpy as np
import json
import toml
import os
from pytubefix import YouTube
import xml.etree.ElementTree as ET

# --- CONFIGURA√á√ÉO INICIAL DA P√ÅGINA ---
st.set_page_config(
    page_title="MiudinhoAI v2.0",
    page_icon="ü§ñ",
    layout="wide"
)

# --- 1. CONFIGURA√á√ÉO DE SEGURAN√áA (API KEY) ---
GEMINI_API_KEY = None

# Tenta ler do Streamlit Cloud (Secrets)
try:
    if "GEMINI_API_KEY" in st.secrets:
        GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except Exception:
    pass

# Se n√£o achou, tenta ler localmente (ajuste o caminho se necess√°rio)
if not GEMINI_API_KEY:
    # Caminho local de backup (apenas para seu uso no VSCode)
    CAMINHO_SECRETS_LOCAL = r"C:\Users\bruno\OneDrive\Projetos Python\14) MIUDINHO.AI\.streamlit\secrets.toml"
    try:
        if os.path.exists(CAMINHO_SECRETS_LOCAL):
            with open(CAMINHO_SECRETS_LOCAL, "r") as f:
                config = toml.load(f)
                GEMINI_API_KEY = config.get("GEMINI_API_KEY")
    except Exception:
        pass

if not GEMINI_API_KEY:
    st.error("‚ùå ERRO: Chave de API n√£o encontrada.")
    st.info("Configure o arquivo .streamlit/secrets.toml para execu√ß√£o local ou adicione aos Secrets do Streamlit Cloud.")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)

# --- MODELOS E CONSTANTES ---
# Usando o Flash para ser r√°pido na busca e rerank
MODELO_RERANK = 'gemini-2.5-flash' 
# Usando o Pro ou Flash para a resposta final (Flash √© mais r√°pido, Pro √© mais detalhado)
MODELO_RESPOSTA = 'gemini-2.5-flash' 
MODELO_EMBEDDING = 'models/text-embedding-004'

# Caminhos (Usando caminhos relativos para funcionar no Github/Cloud)
# Certifique-se que os arquivos est√£o na raiz ou na pasta correta no Git
# Se estiver rodando local e der erro, volte para o caminho absoluto.
FAISS_INDEX_FILE = 'banco_vetorial_gemini_srt_900.index'
CHUNKS_MAPPING_FILE = 'chunks_mapeamento_gemini_srt_900.pkl'
VIDEO_JSON_FILE = 'videos_miudinho_uberaba.json'

# --- FUN√á√ïES DE CARREGAMENTO (CACHE) ---

@st.cache_resource
def load_faiss_index():
    """Carrega o √≠ndice FAISS e os metadados."""
    try:
        # Tenta carregar. Se n√£o achar, tenta caminho absoluto (fallback local)
        if not os.path.exists(FAISS_INDEX_FILE):
             # Fallback para seu caminho local absoluto se o relativo falhar
             caminho_abs_index = r'C:\Users\bruno\OneDrive\Projetos Python\14) MIUDINHO.AI\banco_vetorial_gemini_srt_900.index'
             caminho_abs_pkl = r'C:\Users\bruno\OneDrive\Projetos Python\14) MIUDINHO.AI\chunks_mapeamento_gemini_srt_900.pkl'
             if os.path.exists(caminho_abs_index):
                 index = faiss.read_index(caminho_abs_index)
                 with open(caminho_abs_pkl, 'rb') as f:
                     metadata = pickle.load(f)
                 return index, metadata
        
        # Carregamento padr√£o (Cloud/Git)
        index = faiss.read_index(FAISS_INDEX_FILE)
        with open(CHUNKS_MAPPING_FILE, 'rb') as f:
            metadata = pickle.load(f)
        return index, metadata
        
    except Exception as e:
        st.error(f"Erro ao carregar banco de dados: {e}")
        return None, None

@st.cache_data
def load_video_data():
    """Carrega o JSON dos v√≠deos."""
    try:
        if os.path.exists(VIDEO_JSON_FILE):
            with open(VIDEO_JSON_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
             # Fallback local
             caminho_abs_json = r'C:\Users\bruno\OneDrive\Projetos Python\14) MIUDINHO.AI\videos_miudinho_uberaba.json'
             if os.path.exists(caminho_abs_json):
                with open(caminho_abs_json, 'r', encoding='utf-8') as f:
                    return json.load(f)
        return []
    except Exception:
        return []

# --- L√ìGICA DE INTELIG√äNCIA (RAG + VIDEO) ---

def expand_query(user_query):
    """Gera varia√ß√µes da pergunta."""
    try:
        model = genai.GenerativeModel(MODELO_RERANK)
        prompt = f"""
        Gere 3 formas diferentes de perguntar: "{user_query}"
        Foque em sin√¥nimos teol√≥gicos e palavras-chave relacionadas a estudos b√≠blicos.
        Retorne apenas as perguntas, uma por linha.
        """
        response = model.generate_content(prompt)
        variations = [line.strip() for line in response.text.split('\n') if line.strip()]
        return [user_query] + variations
    except:
        return [user_query]

def rerank_chunks(query, chunks, top_n=7):
    """
    Reordena os chunks para garantir relev√¢ncia, mas mant√©m um n√∫mero saud√°vel (top_n=7)
    para n√£o encurtar demais a resposta final.
    """
    if not chunks:
        return []
        
    # Monta texto para o Gemini avaliar
    candidatos_txt = ""
    for i, c in enumerate(chunks):
        candidatos_txt += f"ID_{i}: {c['text'][:400]}...\n\n" # Envia s√≥ o come√ßo para economizar

    prompt = f"""
    Analise a pergunta: "{query}"
    Classifique os trechos abaixo por relev√¢ncia para responder essa pergunta.
    
    TRECHOS:
    {candidatos_txt}
    
    Retorne APENAS os IDs dos {top_n} melhores, ordenados do mais relevante para o menos, separados por v√≠rgula.
    Exemplo: ID_2, ID_0, ID_5
    """
    
    try:
        model = genai.GenerativeModel(MODELO_RERANK)
        response = model.generate_content(prompt)
        ids_str = response.text.replace("ID_", "").split(",")
        indices = []
        for x in ids_str:
            try:
                idx = int(x.strip())
                if 0 <= idx < len(chunks):
                    indices.append(idx)
            except:
                continue
        
        results = [chunks[i] for i in indices]
        # Se o rerank falhar ou retornar vazio, devolve os originais (fallback)
        return results if results else chunks[:top_n]
    except:
        return chunks[:top_n]

def get_video_transcript(url):
    """Pega a legenda do YouTube via Pytubefix."""
    try:
        yt = YouTube(url)
        # Tenta v√°rias tags de idioma pt
        caption = None
        for lang in ['pt', 'pt-BR', 'a.pt']:
            if lang in yt.captions:
                caption = yt.captions[lang]
                break
        
        if not caption:
            return None
            
        xml_captions = caption.xml_captions
        root = ET.fromstring(xml_captions)
        lines = [elem.text for elem in root.iter('text') if elem.text]
        return " ".join(lines)
    except Exception as e:
        st.error(f"Erro ao obter legenda: {e}")
        return None

# --- INTERFACE PRINCIPAL ---

def main():
    st.title("ü§ñ MiudinhoAI - Central de Conhecimento")
    
    tab1, tab2 = st.tabs(["üîç Busca Global (Acervo)", "üé¨ An√°lise de V√≠deo Individual"])
    
    # --- ABA 1: BUSCA GLOBAL ---
    with tab1:
        st.header("Pesquise em todo o canal")
        st.caption("O sistema busca o momento exato da fala nos v√≠deos.")
        
        index, metadata = load_faiss_index()
        query = st.text_input("Qual sua d√∫vida teol√≥gica ou curiosidade?", key="search_box")
        
        if st.button("Pesquisar no Acervo", type="primary"):
            if not index or not query:
                st.warning("Banco de dados n√£o carregado ou busca vazia.")
            else:
                status = st.status("üïµÔ∏è Processando sua busca...", expanded=True)
                
                # 1. Expans√£o
                status.write("Expandindo termos da pesquisa...")
                queries = expand_query(query)
                
                # 2. Busca Vetorial (Pega bastante coisa para filtrar depois)
                status.write("Varrendo banco de dados...")
                chunk_results = []
                model_emb = genai.EmbedContentModel(model=MODELO_EMBEDDING)
                
                # Faz embedding de todas as varia√ß√µes
                embeddings = model_emb.embed_content(content=queries, task_type="RETRIEVAL_QUERY")['embedding']
                
                # Busca no FAISS
                D, I = index.search(np.array(embeddings), k=10) # 10 por varia√ß√£o
                
                # Deduplica√ß√£o
                seen_indices = set()
                candidates = []
                for row in I:
                    for idx in row:
                        if idx != -1 and idx not in seen_indices:
                            seen_indices.add(idx)
                            if idx < len(metadata):
                                candidates.append(metadata[idx])
                
                # 3. Rerank (O Refinamento)
                status.write(f"Analisando {len(candidates)} trechos encontrados...")
                # Aumentei o top_n para 7 para garantir resposta longa
                final_chunks = rerank_chunks(query, candidates, top_n=7) 
                
                status.update(label="‚úÖ Busca conclu√≠da!", state="complete", expanded=False)
                
                # 4. Gera√ß√£o da Resposta
                if final_chunks:
                    st.subheader("üìù Resposta Sintetizada")
                    
                    contexto = ""
                    for c in final_chunks:
                        contexto += f"Fonte: {c['source_file']}\nTexto: {c['text']}\n\n"
                    
                    prompt_resposta = f"""
                    Use os trechos abaixo para responder a pergunta: "{query}".
                    
                    TRECHOS:
                    {contexto}
                    
                    Instru√ß√µes:
                    1. Seja DETALHADO e did√°tico. Explique bem o conceito.
                    2. Se houver diverg√™ncia nos trechos, mencione.
                    3. Cite o nome do arquivo fonte entre par√™nteses quando usar uma informa√ß√£o.
                    """
                    
                    with st.spinner("Escrevendo resposta..."):
                        model_resp = genai.GenerativeModel(MODELO_RESPOSTA)
                        res = model_resp.generate_content(prompt_resposta)
                        st.markdown(res.text)
                    
                    st.divider()
                    st.subheader("üì∫ Fontes Encontradas (Clique para assistir)")
                    
                    # Layout: V√≠deo na Esquerda, Texto na Direita
                    for i, chunk in enumerate(final_chunks):
                        with st.expander(f"Fonte {i+1}: {chunk['source_file']} (Ver trecho)", expanded=True):
                            col_video, col_text = st.columns([1, 1.2]) # Ajuste de propor√ß√£o
                            
                            with col_video:
                                url = chunk.get('url')
                                time = int(chunk.get('start_time', 0))
                                if url:
                                    st.video(url, start_time=time)
                                    st.caption(f"Inicia em: {time}s")
                                else:
                                    st.image("https://via.placeholder.com/300x169?text=Sem+URL")
                            
                            with col_text:
                                st.markdown("**Transcri√ß√£o:**")
                                st.info(chunk['text'])
                else:
                    st.warning("Nenhum conte√∫do relevante encontrado.")

    # --- ABA 2: AN√ÅLISE INDIVIDUAL ---
    with tab2:
        st.header("Analise um v√≠deo espec√≠fico")
        videos = load_video_data()
        
        if not videos:
            st.warning("Arquivo 'videos_miudinho_uberaba.json' n√£o encontrado.")
        else:
            titulos = [v['titulo'] for v in videos]
            escolha = st.selectbox("Selecione o v√≠deo:", titulos)
            
            video_selecionado = next((v for v in videos if v['titulo'] == escolha), None)
            
            if video_selecionado:
                st.video(video_selecionado['url'])
                
                if st.button("Gerar Resumo e An√°lise deste V√≠deo"):
                    with st.spinner("Baixando legendas e analisando..."):
                        transcript = get_video_transcript(video_selecionado['url'])
                        
                        if transcript:
                            prompt_analise = f"""
                            Analise a seguinte transcri√ß√£o de v√≠deo do canal 'Miudinho Uberaba'.
                            T√≠tulo: {video_selecionado['titulo']}
                            Descri√ß√£o/Vers√≠culo: {video_selecionado.get('descricao', '')}
                            
                            Transcri√ß√£o:
                            {transcript[:25000]}  # Limite de caracteres para seguran√ßa
                            
                            Gere:
                            1. Um resumo dos principais pontos teol√≥gicos (bullets).
                            2. Explica√ß√£o de como o vers√≠culo chave foi abordado.
                            3. Lista de livros ou autores citados (se houver).
                            """
                            model_analise = genai.GenerativeModel('gemini-1.5-flash')
                            res_analise = model_analise.generate_content(prompt_analise)
                            
                            st.markdown("### üìä An√°lise do V√≠deo")
                            st.markdown(res_analise.text)
                        else:
                            st.error("N√£o foi poss√≠vel obter a legenda deste v√≠deo (pode n√£o ter legenda em PT).")

if __name__ == "__main__":
    main()